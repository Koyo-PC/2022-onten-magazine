---
title: 3000円で無線VRトラッカーを自作してみた
author: ZOI
---

どうもこんにちは、ZOIです。
みなさん、「VR」って知ってますか?
あのゴーグルを被るやつです。
実はVRってゴーグルをかぶって終わりじゃないんです。
最近のVRって結構進化していて、顔の向きに合わせて映像の向きを変えるだけじゃなくて、例えば手の位置や握り方を判別してくれたり、実際に歩いたらVR上でも前に進んだりします。
それ以外にも、自分の体の形をVRに反映してくれるような機械もあります。
この記事では「VRに自分の動きを反映する」ような機械を自分で作ってみたので、それの解説をしてみようと思います。

## 1. VRトラッカーって何?

まず初めに、記事のタイトルにもある「VRトラッカー」とはなんなのかから説明していきます。
トラッカーっていうのは下の画像みたいなもので(形は様々ですが)、基本的には「部屋の中でトラッカーがどこにあるのかわかるやつ」です。
![VIVE Tracker](https://www.vive.com/media/filer_public/fed-assets/tracker3/images/introducing-tracker-1366.jpg)
規模が小さいGPSみたいなものです。

普通にVRをしているだけでもヘッドセットの位置やコントローラの位置は把握してくれるんですが、これを手や足につけることで手や足の動きもVRに映し出すことができるというわけです。
VRで綺麗に座る・歩くことができ、寝ることすらできるようになります。

じゃあこれを買えばいいじゃん、という話なんですが、そういうわけにもいかないんです。
その理由は、これの値段にあります。なんとこの機械、一つで**17,500円**します。(2022/3/13)
さらに、十分にトラッキングするには少なくとも腰と両足で3ついるので、52,500円です。
僕が使ってるOculus Quest 2ならもう一つ買ってお釣りがくるレベルです。
ちょっと遊ぶには高すぎるんですよね。

僕以外にも同じようなことを考えている人がいるらしく、もっと安く体のトラッキングができる方法もいろいろ作られています。

例えば、

- HaritoraX (¥27,900)
- Uni-motion (予約販売のみ)
- Tundra Tracker (開発中)
- Kinect (¥15,000弱 Xbox用のものを流用)

などです。

ですが、体の形を近似するだけのデバイスならもっと安く作れるのでは? ということで、VRトラッカーの最安値を目指して自分で作ってみることにしました。

## 2. 色々なトラッカーの仕組み

まず、どうやって3次元の座標を作りだすか考えないといけません。

### 2a. GPS

とりあえず初めに思いつくのはGPSを使ってなんとかすることですが、GPSは(民生用のものでは)かなりの誤差(10mくらい)が出てしまいます。
腕の動きは数cmの精度で測る必要があるので、ちょっと厳しいです。

### 2b. 自作GPS

GPSで地球上の位置を特定できるなら、部屋1つ分の大きさのGPSを作ればかなりの精度で測定できるのでは...?

と思ったんですが、少し調べてみたところ、光の速度を利用しているとか、人工衛星の運動での相対性理論や重力場によって時間の流れが変わるとか、そのレベルの厳密な計算をしてるらしいので、ちょっと自宅で実現するのは無理そうです。

### 2c. VIVE Trackerの方法

さっき紹介したVIVEトラッカーに使われてる方法を見てみましょう。
あのトラッカーを使う時には、ベースステーションっていう機械を2個以上置く必要があります。
そこから赤外線を出して、あたった時間のズレでトラッカーの位置を判断するようになっています。

参考: <https://youtu.be/J54dotTt7k0>

ただこの方法、できるだけリアルタイムで表示するために、数十〜数百μs間隔で信号を送っているらしいです。この時間での制御はコスト的に難しそうで、かつ検出角度が1度ずれるだけでもかなりの誤差になるので、無理そうです。

### 2d. カメラでAIに持ち込む方法

ちょっと変わったやり方として、「全身をカメラに納め、AIを使って姿勢を推定する」という方法があります。
この方法では、スマホカメラを使う仕組みにすれば何も機材が要らないので、アプリ開発費を無視すれば無料で作ることができます。
ただ、この方法を考えている人はいっぱいいて、個人ではIT大手に勝てそうにないので、今回は使わないです。
(あとAIの精度あんまり信じていないです...)

### 2e. 加速度センサの利用

このセンサーで得たい情報は、「センサをつけた場所の部屋での位置」だけです。つまり、最初の位置さえ記録しておけば、そこからの加速度を2回積分することでどれだけ動いたかがわかるということです。

このためには加速度センサとジャイロセンサ(回転速度を測る)を使えばいいんですが、速度ではなく加速度を使っているので、僕の技術で誤差をどれだけ減らせるかというのが心配です。ちょっとミスると、腕が永久に向こうへ移動していくトラッカーができてしまいます...
あと、小型のジャイロセンサとして有名な`ENC-03RC/D`を使うと、3軸の回転を測るために3つのセンサを90度ずつずらして配置する必要があります。部品1つ1つは小さいのですが、立体的に組むとなると結構な分厚さになるのでは...?という感じです。(それでもVIVEより小さいと思いますが)

## 3. この記事で作るトラッカーの仕組み

じゃあどうやって作るんだという話なんですが、ここで人間の体で動くのはどこなのか、ということを考えてみましょう。
この話題はゲーム制作の現場ではよく考えれらていて(キャラクターをできるだけリアルに動かすためです)、「Humanoidボーン」という形である程度規格化されています。
特に、VRChatに使えるボーンというのはBoothにいっぱい転がっています。以下のような感じです。

![Boothのスクリーンショット](Assets/Image/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88%202022-03-13%2012.16.30.png)

さて、これで何が言いたかったかというと、「たったこれだけのボーンの角度を変えることで人の姿勢が作れる」ということです。例えば足の関節以外のところは曲がりません。

つまり、それぞれの骨の角度さえわかれば、体全体の姿勢がわかるのではないか?ということです。

ということで、この方法で作っていきます!

## 4. 素材集め

### 4a. 部品の選定

まず、どのようにして角度を取るかです。
一般的にはジャイロセンサを使うのですが、それでは[方法2e](#2e-加速度センサの利用)と変わりません。

重力に対しての傾きを検出するセンサはないのかとも考えましたが、よく考えるとジャンプなどで大きな加速度がかかった時にズレそうです。

そこで今回は、加速度がかかってもズレず、周りが塞がっていても検出できそうなセンサとして、`地磁気センサ`を使うことにしました。

後でまた問題になりますが、地磁気センサは結構扱いが難しいです。まあそこはソフトウェアでなんとかすることにしましょう。

というわけで、今回使う材料は、ざっと以下の通りです!

- 地磁気センサ GY-273 (チップ : HMC5883L)
- Arduino Uno (センサの読み取り・PCへの送信用)
- ユニバーサル基板 (配線用)
- 導線 (センサ・マイコンの通信用)
- 面ファスナー・リボン (体への固定用)

### 4b. 購入

とりあえず、上で挙げた部品を普通に買うとどのくらいするのか考えてみます。

| 品名         | 価格         | 備考               |
| :----------- | -----------: | :----------------- |
| GY-273       | 約 `¥600` x6 | Amazon             |
| Arduino Uno  | `¥3,300`     | スイッチサイエンス |
| 基板 ICB-288 | `¥110`       | Amazon             |
| ビニール線   | `¥140`       | Amazon             |
| スズメッキ線 | `¥131`       | Amazon             |
| 平ゴム       | `¥285`       | Amazon             |
|              |              | (全て送料抜き)     |

うーん、ちょっと高いですね。特にセンサとマイコン。
送料は大阪のシリコンハウスあたりまで行って買えばいいんですが...
そこで、半導体たちをもっと安く買えるショップを探してみます。

AliExpressというショップを知っていますか?
中国のアリババグループ(Alipayの運営)が運営しているサイトで、多くの場合Amazonよりも安く買えることが特徴です(特に原価が安そうな電子部品)。
というわけで、ここで探してみるとこれくらいの価格で買えそうです。

| 品名        | 価格         | 備考           |
| :---------- | -----------: | :------------- |
| GY-273      | 約 `¥150` x6 | AliExpress     |
| Arduino Uno | `¥850`       | AliExpress     |
|             |              | (全て送料抜き) |

出品されているものはすぐに変わるのであくまで目安ですが、めっちゃ安くなりましたね。
ただし、(AliExpressの特徴ですが)届くのに数ヶ月かかる場合があります。
早く手に入れたい人は諦めてAmazonで買いましょう。

僕がGY-273を買ったときは16日で届きました。
(ちなみに配送予定は信じない方がいいです。1週間早く届きました。)

※ 僕は家にある部品を使うので、ここで書いている部品とは違うものを使う場合があります。

## 5. 作ってみる

### 5-0. なんとなく計画

どんな流れで処理するかだけ決めておきましょう。

1. 地磁気センサのデータをマイコンへ送信
2. マイコンからデータをPCへ送信
3. PCアプリでセンサのキャリブレーションをする
4. PCアプリでセンサの値を角度(クォータニオン)に変換
5. PCアプリでHMDの位置を取得
6. PCアプリで骨の長さ・HMD位置から各頂点の位置・向きを取得

`1.`から順に作っていきます。

### 5-1. 地磁気センサのデータをマイコンへ送信

#### 5-1a. データの取得

まずセンサからデータを取得してみます。
センサとマイコンの通信にはI2Cという方法を使います。
この方法では、一組の信号線を全てのパーツにつなげるだけで、そのパーツ全てとデータのやり取りができるようになります。
なので、今回のように6個もセンサを使う場合はいいのでは?!
と思ったのですが、なんとパーツのアドレスが変更できないことが判明しました...
マイコンを6つ買うのは色々と問題があるので、今回は黒魔術な方法でごまかします。

#### 5-1b. マイコンの設定

さて、さっきI2Cのアドレス重複でやらかしましたが、それについて調べてる間に、どうやらI2Cはノイズに弱いことが判明しました。
元々はマイコンとしてArduinoを使い、有線でパソコンに繋ごうとしていたのですが、1mくらいが限界らしいので予定変更です。
通信機兼マイコンとして、TWE-LITEを使うことにします。

TWE-LITEは結構高性能なマイコンを内蔵していて、それで実行するコードを自分で書けるのですが、組み込みみたいな見た目をしていてめちゃくちゃ使いにくいらしいです。
Arduinoは書きやすいので、TWE-LITEをまるでArduinoのように見えるように加工します。

参考、というかこれ→<https://qiita.com/soburi/items/0b0aa3d0c4332a5e7a4c>

基本この記事そのままやってもらえればいいのですが、「TWE-Lite Rなんて持ってないぞ?」となった人がほとんどだと思います。
これはチップにコードを書き込むパーツなのですが、FTDIのUSB-シリアル変換ケーブルならなんでも良さそうです。
僕はスイッチサイエンスのものを使いました。

#### 5-1c. I2C通信(+黒魔術)

こちらを参考にさせてもらいました→<https://picalittle.blog.fc2.com/blog-entry-68.html>

### 5-2. Arduino UnoからデータをPCへ送信

### 5-3. PCアプリでセンサのキャリブレーションをする

### 5-4. PCアプリでセンサの値を角度(クォータニオン)に変換

### 5-5. PCアプリでHMDの位置を取得

### 5-6. PCアプリで骨の長さ・HMD位置から各頂点の位置・向きを取得

とりあえずアプリのことは考えずにやってみます。

こんなコードでいい感じに位置を手に入れられます。

```csharp
using System;
using System.Numerics;
using System.Threading;
using OVRSharp;
using OVRSharp.Exceptions;
using OVRSharp.Math;
using Valve.VR;

namespace GetHMDLoc
{
    class Program
    {
        static void Main(string[] args)
        {
            Application app;
            try {
                app = new Application(Application.ApplicationType.Overlay);
            } catch (OpenVRSystemException<EVRInitError> e) {
                Console.Error.WriteLine("ERROR : " + e);
                return;
            }

            var data = new TrackedDevicePose_t[100];

            while (true)
            {
                app.OVRSystem.GetDeviceToAbsoluteTrackingPose(ETrackingUniverseOrigin.TrackingUniverseStanding, 0, data);

                var pose = data[0].mDeviceToAbsoluteTracking.ToMatrix4x4();

                Matrix4x4.Decompose(pose, out _, out var rotation, out var translation);
                Console.Write("translation: " + translation + "\n");
                Console.Write("rotation: " + rotation + "\n\n");
                Thread.Sleep(1000);
            }
        }
    }
}
```

実行時の出力:

```plaintext
...

translation: <-0.12683892, 0.8559739, -0.16179551>
rotation: {X:-0.063213125 Y:0.060422175 Z:0.9941291 W:0.06372233}

translation: <-0.11176507, 0.8112176, -0.15557235>
rotation: {X:0.045767996 Y:-0.013111211 Z:0.011232452 W:0.9988029}

translation: <-0.13694595, 0.77720445, -0.17874679>
rotation: {X:0.04394212 Y:-0.048361007 Z:-0.10624636 W:0.9921905}

translation: <-0.12910175, 0.76790535, -0.18021783>
rotation: {X:-0.024631226 Y:-0.6703547 Z:0.116061494 W:0.7324941}

...
```

### 5-8. PCアプリで骨の長さ・HMD位置から各頂点の位置・向きを取得

### 5-9. PCアプリからVMTにデータをOSCで送る

### 5-10. VMTがSteamVRに信号を送ってくれる

### 5-11. 完成!
